stages:

  generate_user_profiles:
    cmd: >-
      poetry run python -m src.batch_processing.generate_users
      --num_users=${dataset.num_users}
      --categories="technology,sports,music,art"
      data/users_with_sentences.parquet
    deps:
      - src/batch_processing/generate_users.py
    outs:
      - data/users_with_sentences.parquet

  embed_users:
    cmd: >-
      poetry run python -m src.batch_processing.embed_sentences
      data/users_with_sentences.parquet
      data/user_embeddings.parquet
    deps:
      - src/batch_processing/embed_sentences.py
      - data/users_with_sentences.parquet
    outs:
      - data/user_embeddings.parquet

  make_items:
    cmd: >-
      poetry run python -m src.batch_processing.make_dataset
      data/train.parquet
    deps:
      - src/batch_processing/make_dataset.py
    outs:
      - data/train.parquet

  format_items:
    cmd: >-
      poetry run python -m src.batch_processing.format_dataset
      data/train.parquet
      data/formatted_dataset.parquet
      --limit=${dataset.limit}
    deps:
      - src/batch_processing/format_dataset.py
      - data/train.parquet
    outs:
      - data/formatted_dataset.parquet

  embed_items:
    cmd: >-
      poetry run python -m src.batch_processing.embed_sentences
      data/formatted_dataset.parquet
      data/item_embeddings.parquet
      --dimension=${embedding.dimension}
      --model_name=${embedding.model_name}
    deps:
      - src/batch_processing/embed_sentences.py
      - src/model/embedding.py
      - data/formatted_dataset.parquet
    outs:
      - data/item_embeddings.parquet

  generate_history:
    cmd: >-
      poetry run python -m src.batch_processing.generate_history
      data/item_embeddings.parquet
      data/user_embeddings.parquet
      data/user_history.parquet
      --max_views=${dataset.max_views}
    deps:
      - src/batch_processing/generate_history.py
      - data/item_embeddings.parquet
      - data/user_embeddings.parquet
    outs:
      - data/user_history.parquet

  load_users_to_elasticsearch:
    cmd: >-
      poetry run python -m src.batch_processing.load_to_elasticsearch
      --es_host=https://localhost:9200
      --index_name=users_${elastic.index_suffix}
      data/user_translation.parquet
      && echo `date` > data/load_users_timestamp.txt
    deps:
      - src/batch_processing/load_to_elasticsearch.py
      - data/user_translation.parquet
    outs:
      - data/load_users_timestamp.txt

  load_items_to_elasticsearch:
    cmd: >-
      poetry run python -m src.batch_processing.load_to_elasticsearch
      --es_host=https://localhost:9200
      --index_name=item_${elastic.index_suffix}
      data/item_translation.parquet
      && echo `date` > data/load_items_timestamp.txt
    deps:
      - src/batch_processing/load_to_elasticsearch.py
      - data/item_translation.parquet
    outs:
      - data/load_items_timestamp.txt

  use_elasticsearch:
    cmd: >-
      echo use elasticsearch
      && echo `date` > data/use_elasticsearch.txt
    deps:
      - data/load_users_timestamp.txt
      - data/load_items_timestamp.txt
    outs:
      - data/use_elasticsearch.txt

  make_user_translation:
    cmd: >-
      poetry run python -m src.batch_processing.make_user_translation
      data/user_embeddings.parquet
      data/user_translation.parquet
      models/two_tower_model.pth
    deps:
      - src/batch_processing/make_user_translation.py
      - data/user_embeddings.parquet
      - models/two_tower_model.pth
    outs:
      - data/user_translation.parquet

  make_item_translation:
    cmd: >-
      poetry run python -m src.batch_processing.make_item_translation
      data/item_embeddings.parquet
      data/item_translation.parquet
      models/two_tower_model.pth
    deps:
      - src/batch_processing/make_item_translation.py
      - data/item_embeddings.parquet
      - models/two_tower_model.pth
    outs:
      - data/item_translation.parquet

  learn_two_tower_model:
    cmd: >-
      poetry run python -m src.batch_processing.train_two_tower_model
      data/user_history.parquet
      models/two_tower_model.pth
      --epochs=${train.epochs}
      --patience=${train.patience}
    deps:
      - src/batch_processing/train_two_tower_model.py
      - src/model/two_tower_model.py
      - data/user_history.parquet
    outs:
      - models/two_tower_model.pth
